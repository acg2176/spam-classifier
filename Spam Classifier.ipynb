{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv('spam_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "0             0.00                0.64            0.64            0.0   \n",
       "1             0.21                0.28            0.50            0.0   \n",
       "2             0.06                0.00            0.71            0.0   \n",
       "3             0.00                0.00            0.00            0.0   \n",
       "4             0.00                0.00            0.00            0.0   \n",
       "5             0.00                0.00            0.00            0.0   \n",
       "\n",
       "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
       "0            0.32             0.00               0.00                 0.00   \n",
       "1            0.14             0.28               0.21                 0.07   \n",
       "2            1.23             0.19               0.19                 0.12   \n",
       "3            0.63             0.00               0.31                 0.63   \n",
       "4            0.63             0.00               0.31                 0.63   \n",
       "5            1.85             0.00               0.00                 1.85   \n",
       "\n",
       "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
       "0              0.00             0.00  ...          0.00         0.000   \n",
       "1              0.00             0.94  ...          0.00         0.132   \n",
       "2              0.64             0.25  ...          0.01         0.143   \n",
       "3              0.31             0.63  ...          0.00         0.137   \n",
       "4              0.31             0.63  ...          0.00         0.135   \n",
       "5              0.00             0.00  ...          0.00         0.223   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.778         0.000         0.000   \n",
       "1           0.0         0.372         0.180         0.048   \n",
       "2           0.0         0.276         0.184         0.010   \n",
       "3           0.0         0.137         0.000         0.000   \n",
       "4           0.0         0.135         0.000         0.000   \n",
       "5           0.0         0.000         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average:  capital_run_length_longest:  \\\n",
       "0                        3.756                           61   \n",
       "1                        5.114                          101   \n",
       "2                        9.821                          485   \n",
       "3                        3.537                           40   \n",
       "4                        3.537                           40   \n",
       "5                        3.000                           15   \n",
       "\n",
       "   capital_run_length_total:  spam  \n",
       "0                        278     1  \n",
       "1                       1028     1  \n",
       "2                       2259     1  \n",
       "3                        191     1  \n",
       "4                        191     1  \n",
       "5                         54     1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "5            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "5           1.85            0.00              0.00                1.85   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "5             0.00            0.00  ...         0.00        0.223   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "5          0.0        0.000        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "5                       3.000                          15   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "5                        54     1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove : from columns\n",
    "spam.columns = spam.columns.str.rstrip(':')\n",
    "spam.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000  ...  4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413  ...     0.038575     0.139030   \n",
       "std           0.278616        0.644755  ...     0.243471     0.270355   \n",
       "min           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "25%           0.000000        0.000000  ...     0.000000     0.000000   \n",
       "50%           0.000000        0.000000  ...     0.000000     0.065000   \n",
       "75%           0.000000        0.160000  ...     0.000000     0.188000   \n",
       "max           5.260000       18.180000  ...     4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238   \n",
       "std       0.109394     0.815672     0.245882     0.429342   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000   \n",
       "max       4.081000    32.478000     6.003000    19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation of the original dataset here:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\n",
    "\n",
    "### The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a conceptual view and if one had more domain knowledge on what spam emails are, three possible variables would be ```word_freq_money```, ```word_freq_free```, and ```word_freq_credit```. Spam is defined as fraudulent unsolicited emails. These variables look for the percentage of words in the email that match the word money, free, and credit respectively. It is possible that they are important predictors because spam emails would usually ask the recipient to send money to a link, get free benefits/bonuses if they complete a survey for instance, or ask for credit card information or anything else that is personal. So, the higher the frequency of these words, the more likely that it would be detected as spam.\n",
    "\n",
    "\n",
    "Alternatively, an ANOVA test can be used since the output is categorical and the inputs are continuous/numeric inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam.loc[:, spam.columns != 'spam']\n",
    "y = spam['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_your      7.214605e-161\n",
       "word_freq_000       6.730650e-121\n",
       "word_freq_remove    6.791279e-119\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "test = SelectKBest(score_func = f_classif)\n",
    "fit = test.fit(X, y)\n",
    "\n",
    "#get the p-values of the F-scores\n",
    "p_values = pd.Series(fit.pvalues_, index = X.columns)\n",
    "p_values.sort_values(ascending = True, inplace = True)\n",
    "p_values.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ANOVA test shows that the variables with the lowest p - values (highly statistically significant) are ```word_freq_your:```, ```word_freq_000:```, ```word_freq_remove:```. We reject the null hypothesis that these variables do not have a significant relationship (i.e. do not explain the relationship) with the target variable, ```spam```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate distribution of each of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(spam['spam'], cumulative = True, bw = 1.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(spam['word_freq_money'], cumulative = True, bw = 1.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(spam['word_freq_free'], cumulative = True, bw = 1.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(spam['word_freq_credit'], cumulative = True, bw = 1.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare 4 different classifier supervised learning models: Logistic Regression, K-NN, SVM, Random Forest\n",
    "\n",
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 3 variables\n",
    "X = X[['word_freq_money', 'word_freq_free', 'word_freq_credit']]\n",
    "y = spam['spam']\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (UNSCALED DATA)\n",
      "Training set score: 0.78\n",
      "Test set score: 0.78\n",
      "Mean Cross Validation, KFold: 0.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_money</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Coefficients</th>\n",
       "      <td>3.149617</td>\n",
       "      <td>1.506624</td>\n",
       "      <td>3.015413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  word_freq_money  word_freq_free  \\\n",
       "Logistic Regression Coefficients         3.149617        1.506624   \n",
       "\n",
       "                                  word_freq_credit  \n",
       "Logistic Regression Coefficients          3.015413  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (UNSCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X_test, y_test))) \n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, KFold: {:.2f}\".format(np.mean(cross_val_score(logreg, X_train, y_train, cv=kfold))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Organize the model coefficients\n",
    "logreg_coef = pd.DataFrame(data=logreg.coef_, columns=X.columns, index=['Logistic Regression Coefficients'])\n",
    "logreg_coef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "3683       0          0\n",
       "4412       0          1\n",
       "2584       0          0\n",
       "69         1          0\n",
       "1844       0          0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual y values vs. Predicted y values without scaling\n",
    "logreg_predicted_vals = logreg.predict(X_test)\n",
    "lr = pd.DataFrame({'Actual': y_test, 'Predicted': logreg_predicted_vals})\n",
    "lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED DATA)\n",
      "Training set score: 0.79\n",
      "Test set score: 0.78\n",
      "Mean Cross Validation, KFold: 0.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_money</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Scaled Logistic Regression Coefficients</th>\n",
       "      <td>1.591869</td>\n",
       "      <td>1.338695</td>\n",
       "      <td>1.736054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         word_freq_money  word_freq_free  \\\n",
       "Scaled Logistic Regression Coefficients         1.591869        1.338695   \n",
       "\n",
       "                                         word_freq_credit  \n",
       "Scaled Logistic Regression Coefficients          1.736054  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg_scaled = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(logreg_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(logreg_scaled.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, KFold: {:.2f}\".format(np.mean(cross_val_score(logreg_scaled, X_train_scaled, y_train, cv=kfold))))\n",
    "\n",
    "# Organize the model coefficients\n",
    "logreg_scaled_coef = pd.DataFrame(data=logreg_scaled.coef_, columns=X.columns, index=['Scaled Logistic Regression Coefficients'])\n",
    "\n",
    "# Print coefficients for comparison\n",
    "logreg_scaled_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average accuracy score of the Logistic Regression after cross validation is 0.78."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV: tuning hyperparameters of Logistic Regression**\n",
    "\n",
    "The parameters that are tuned are the penalty parameter and the C parameter. The penalty parameter is a regularization parameter--either l1 or l2--that penalizes the coefficient of the logistic regression. This is a step that shrinks the estimate to 0 or towards 0 to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED DATA)\n",
      "best mean cross-validation score: 0.784\n",
      "best parameters: {'C': 1.6666666666666665, 'penalty': 'l1'}\n",
      "test-set score: 0.781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(1, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "log_cv = GridSearchCV(LogisticRegression(solver = 'liblinear', max_iter = 10000, random_state = 43), hyperparameters, cv=kf, verbose=0)\n",
    "\n",
    "log_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED DATA)\")\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(log_cv.best_score_))\n",
    "print(\"best parameters: {}\".format(log_cv.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(log_cv.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters are C = 1.67 and l1 penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFER (UNSCALED DATA)\n",
      "Training set score: 0.84\n",
      "Test set score: 0.82\n",
      "Mean Cross Validation, KFold: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN CLASSIFER (UNSCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(knn.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, KFold: {:.2f}\".format(np.mean(cross_val_score(knn, X_train, y_train, cv=kfold))))\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFER (SCALED DATA)\n",
      "Training set score: 0.84\n",
      "Test set score: 0.82\n",
      "Mean Cross Validation, KFold: 0.82\n"
     ]
    }
   ],
   "source": [
    "knn_scaled = KNeighborsClassifier(n_neighbors = 5).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"KNN CLASSIFER (SCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(knn_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "\n",
    "#Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, KFold: {:.2f}\".format(np.mean(cross_val_score(knn_scaled, X_train_scaled, y_train, cv=kfold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV with KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFIER (SCALED DATA)\n",
      "Test set Score: 0.82\n",
      "Best Parameter: {'kneighborsclassifier__n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "\n",
    "knn_param_grid = {'kneighborsclassifier__n_neighbors': range(1, 10)}\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_param_grid).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"KNN CLASSIFIER (SCALED DATA)\")\n",
    "print(\"Test set Score: {:.2f}\".format(knn_grid.score(X_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(knn_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the parameter value 5 for n_neighbors because after tuning the hyperparameters using GridSearchCV, the best parameter value to use for this model is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Before Gridsearch: 0.78\n",
      "After Gridsearch: 0.78\n",
      "\n",
      "KNN CLASSIFIER\n",
      "Before Gridsearch: 0.82\n",
      "After Gridsearch: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"LOGISTIC REGRESSION\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(logreg_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(log_cv.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFIER\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(knn_grid.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the test accuracy score on both models, the KNN classifier performed better and had a higher accuracy score than the Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pca = PCA(svd_solver='randomized',n_components=3, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR MACHINE (UNSCALED DATA)\n",
      "Training set score: 0.83\n",
      "Test set score: 0.82\n",
      "Mean Cross Validation, Kfold: 0.83\n"
     ]
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"SUPPORT VECTOR MACHINE (UNSCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(svc.score(X_test, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, Kfold: {:.2f}\".format(np.mean(cross_val_score(svc, X_train, y_train, cv=kfold))))\n",
    "\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(SCALED DATA)\n",
      "Training set score: 0.83\n",
      "Test set score: 0.82\n",
      "Mean Cross Validation, KFold: 0.83\n"
     ]
    }
   ],
   "source": [
    "svc_scaled = SVC().fit(X_train_scaled, y_train)\n",
    "print(\"SVC(SCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(svc_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(svc_scaled.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, KFold: {:.2f}\".format(np.mean(cross_val_score(svc_scaled, \n",
    "                                                                            X_train_scaled, \n",
    "                                                                            y_train, \n",
    "                                                                            cv=kfold))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR MACHINE (SCALED DATA)\n",
      "Test set score: 0.81\n",
      "Best Parameter: {'svc__C': 50, 'svc__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = make_pipeline(StandardScaler(),pca,svc)\n",
    "svc_param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "svc_grid = GridSearchCV(svc_pipe, svc_param_grid, cv = kfold).fit(X_train_scaled, y_train)\n",
    "print(\"SUPPORT VECTOR MACHINE (SCALED DATA)\")\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(svc_grid.score(X_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(svc_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main parameters to choose for the SVM model are the C parameter and the gamma parameter. The best ones are chosen via GridSearchCV. These are 50 for the C parameter and 0.005 for gamma. The gamma defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. C acts as a regularization parameter for the support vector machine: a higher C means that the optimizer will choose a smaller margin hyperplane to get a better accuracy while a lower C means the optimizer will choose a larger margin at the cost of training accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Scores on the Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Before Gridsearch: 0.78\n",
      "After Gridsearch: 0.78\n",
      "\n",
      "KNN CLASSIFIER\n",
      "Before Gridsearch: 0.82\n",
      "After Gridsearch: 0.82\n",
      "\n",
      "SUPPORT VECTOR MACHINE\n",
      "Before Gridsearch: 0.82\n",
      "After Gridsearch: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"LOGISTIC REGRESSION\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(logreg_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(log_cv.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFIER\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(knn_grid.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"SUPPORT VECTOR MACHINE\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(svc_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(svc_grid.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on 3 models, it looks like KNN performed the best on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFER (UNSCALED DATA)\n",
      "Training set score: 0.86\n",
      "Test set score: 0.82\n",
      "Mean Cross Validation, Kfold: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 79).fit(X_train, y_train)\n",
    "\n",
    "print(\"RANDOM FOREST CLASSIFER (UNSCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(rf.score(X_test, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, Kfold: {:.2f}\".format(np.mean(cross_val_score(rf, X_train, y_train, cv=kfold))))\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFER (SCALED DATA)\n",
      "Training set score: 0.86\n",
      "Test set score: 0.81\n",
      "Mean Cross Validation, Kfold: 0.82\n"
     ]
    }
   ],
   "source": [
    "rf_scaled = RandomForestClassifier(n_estimators = 79).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"RANDOM FOREST CLASSIFER (SCALED DATA)\")\n",
    "print(\"Training set score: {:.2f}\".format(rf_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(rf_scaled.score(X_test_scaled, y_test)))\n",
    "\n",
    "# Kfold Cross Validation\n",
    "print(\"Mean Cross Validation, Kfold: {:.2f}\".format(np.mean(cross_val_score(rf_scaled, \n",
    "                                                                            X_train_scaled, \n",
    "                                                                            y_train, \n",
    "                                                                            cv=kfold))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFIER (SCALED DATA)\n",
      "Test set Score: 0.81\n",
      "Best Parameter: {'randomforestclassifier__n_estimators': 26}\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "rf_param_grid = {'randomforestclassifier__n_estimators': range(10,100)}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_param_grid, cv = kfold).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"RANDOM FOREST CLASSIFIER (SCALED DATA)\")\n",
    "print(\"Test set Score: {:.2f}\".format(rf_grid.score(X_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(rf_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter to be chosen for the Random Forest Classifier is the n estimator. GridSearchCV chose 15 as the n estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Scores on the Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "Before Gridsearch: 0.78\n",
      "After Gridsearch: 0.78\n",
      "\n",
      "KNN CLASSIFIER\n",
      "Before Gridsearch: 0.82\n",
      "After Gridsearch: 0.82\n",
      "\n",
      "SUPPORT VECTOR MACHINE\n",
      "Before Gridsearch: 0.82\n",
      "After Gridsearch: 0.81\n",
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "Before Gridsearch: 0.81\n",
      "After Gridsearch: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"LOGISTIC REGRESSION\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(logreg_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(log_cv.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFIER\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(knn_grid.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"SUPPORT VECTOR MACHINE\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(svc_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(svc_grid.score(X_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "print(\"Before Gridsearch: {:.2f}\".format(rf_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(rf_grid.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on all 4 models, KNN performed the best on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding 3 more variables after using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_money</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_credit</th>\n",
       "      <th>word_freq_your</th>\n",
       "      <th>word_freq_000</th>\n",
       "      <th>word_freq_remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_money  word_freq_free  word_freq_credit  word_freq_your  \\\n",
       "0                0.00            0.32              0.00            0.96   \n",
       "1                0.43            0.14              0.00            1.59   \n",
       "2                0.06            0.06              0.32            0.51   \n",
       "3                0.00            0.31              0.00            0.31   \n",
       "4                0.00            0.31              0.00            0.31   \n",
       "...               ...             ...               ...             ...   \n",
       "4596             0.00            0.00              0.00            0.00   \n",
       "4597             0.00            0.00              0.00            2.00   \n",
       "4598             0.00            0.00              0.00            0.30   \n",
       "4599             0.00            0.00              0.00            0.32   \n",
       "4600             0.00            0.00              0.00            0.65   \n",
       "\n",
       "      word_freq_000  word_freq_remove  \n",
       "0              0.00              0.00  \n",
       "1              0.43              0.21  \n",
       "2              1.16              0.19  \n",
       "3              0.00              0.31  \n",
       "4              0.00              0.31  \n",
       "...             ...               ...  \n",
       "4596           0.00              0.00  \n",
       "4597           0.00              0.00  \n",
       "4598           0.00              0.00  \n",
       "4599           0.00              0.00  \n",
       "4600           0.00              0.00  \n",
       "\n",
       "[4601 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = spam.loc[:, spam.columns != 'spam']\n",
    "X_new = X_new[['word_freq_money', 'word_freq_free', 'word_freq_credit', \n",
    "              'word_freq_your', 'word_freq_000', 'word_freq_remove']]\n",
    "\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFICATION (SCALED DATA)\n",
      "Test set Score: 0.88\n",
      "Best Parameter: {'kneighborsclassifier__n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, random_state = 42)\n",
    "\n",
    "#scale data\n",
    "scaler_new = preprocessing.StandardScaler().fit(X_train)\n",
    "X_new_train_scaled = scaler_new.transform(X_train)\n",
    "X_new_test_scaled = scaler_new.transform(X_test)\n",
    "\n",
    "\n",
    "knn_new_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "\n",
    "#GridSearch CV on scaled data\n",
    "knn_new_param_grid = {'kneighborsclassifier__n_neighbors': range(1, 10)}\n",
    "knn_new_grid = GridSearchCV(knn_new_pipe, knn_new_param_grid).fit(X_new_train_scaled, y_train)\n",
    "\n",
    "print(\"KNN CLASSIFICATION (SCALED DATA)\")\n",
    "print(\"Test set Score: {:.2f}\".format(knn_new_grid.score(X_new_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(knn_new_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of 3 more variables increased the accuracy score of the model from 0.82 to 0.88 in the previous KNN classifier. Now, the parameter n_neighbors increased from 5 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerunning all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED DATA)\n",
      "best mean cross-validation score: 0.846\n",
      "best parameters: {'C': 1.0, 'penalty': 'l1'}\n",
      "test-set score: 0.846\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = np.linspace(1, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "log_new_cv = GridSearchCV(LogisticRegression(solver = 'liblinear', \n",
    "                                             max_iter = 10000, random_state = 43), \n",
    "                          hyperparameters, cv=kf, verbose=0)\n",
    "\n",
    "log_new_cv.fit(X_new_train_scaled, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED DATA)\")\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(log_new_cv.best_score_))\n",
    "print(\"best parameters: {}\".format(log_new_cv.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(log_new_cv.score(X_new_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR MACHINE (SCALED DATA)\n",
      "Test set score: 0.84\n",
      "Best Parameter: {'svc__C': 10, 'svc__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "svc_new_pipe = make_pipeline(StandardScaler(),pca,svc)\n",
    "svc_new_param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "svc_new_grid = GridSearchCV(svc_new_pipe, svc_new_param_grid, cv = kfold).fit(X_new_train_scaled, y_train)\n",
    "\n",
    "print(\"SUPPORT VECTOR MACHINE (SCALED DATA)\")\n",
    "print(\"Test set score: {:.2f}\".format(svc_new_grid.score(X_new_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(svc_new_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFIER (SCALED DATA)\n",
      "Test set Score: 0.89\n",
      "Best Parameter: {'randomforestclassifier__n_estimators': 84}\n"
     ]
    }
   ],
   "source": [
    "rf_new_pipe = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "rf_new_param_grid = {'randomforestclassifier__n_estimators': range(10,100)}\n",
    "rf_new_grid = GridSearchCV(rf_new_pipe, rf_new_param_grid, cv = kfold).fit(X_new_train_scaled, y_train)\n",
    "\n",
    "print(\"RANDOM FOREST CLASSIFIER (SCALED DATA)\")\n",
    "print(\"Test set Score: {:.2f}\".format(rf_new_grid.score(X_new_test_scaled, y_test)))\n",
    "print(\"Best Parameter: {}\".format(rf_new_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION\n",
      "After Gridsearch: 0.85\n",
      "\n",
      "KNN CLASSIFIER\n",
      "After Gridsearch: 0.88\n",
      "\n",
      "SUPPORT VECTOR MACHINE\n",
      "After Gridsearch: 0.84\n",
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "After Gridsearch: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"LOGISTIC REGRESSION\")\n",
    "#print(\"Before Gridsearch: {:.2f}\".format(logreg_scaled.score(X_new_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(log_new_cv.score(X_new_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"KNN CLASSIFIER\")\n",
    "#print(\"Before Gridsearch: {:.2f}\".format(knn_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(knn_new_grid.score(X_new_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"SUPPORT VECTOR MACHINE\")\n",
    "#print(\"Before Gridsearch: {:.2f}\".format(svc_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(svc_new_grid.score(X_new_test_scaled, y_test)))\n",
    "print(\"\")\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "#print(\"Before Gridsearch: {:.2f}\".format(rf_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"After Gridsearch: {:.2f}\".format(rf_new_grid.score(X_new_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models performed better after adding 3 more variables. **Random Forest classifier** had the highest performance on accuracy score on the test data with a score of 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[646  30]\n",
      " [ 95 380]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_new_pred_rf = rf_new_grid.predict(X_new_test_scaled)\n",
    "confusion_matrix = confusion_matrix(y_test, y_new_pred_rf)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that there are 1026 true predictions (True Positive + True Negative) and there are 125 false predictions (False Positives + False Negatives).\n",
    "The Precision scores are relatively high which is the ratio of correctly predicted positive values over the total predicted positive values. The accuracy score is 0.89 which is the ratio of all correctly predicted positive and negative values over the total number of observations. The recall (ratio of correctly predicted positive values over all observations in the class) and f1 scores (weight average of precision and recall) are also relatively high.\n",
    "\n",
    "Thus, the Random Forest Classifier had the highest performance amongst all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       676\n",
      "           1       0.93      0.80      0.86       475\n",
      "\n",
      "    accuracy                           0.89      1151\n",
      "   macro avg       0.90      0.88      0.89      1151\n",
      "weighted avg       0.89      0.89      0.89      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report for Random Forest\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_new_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The SPAM classifier that performed the best is the Random Forest Classifier with an 89% accuracy, using 6 variables from the spam dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
